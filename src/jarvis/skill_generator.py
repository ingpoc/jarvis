"""Skill generation: autonomous skill creation from recurring patterns.

When a pattern is detected 3+ times:
1. Retrieve candidate from skill_candidates table
2. Generate SKILL.md using GLM 4.7 (or template fallback)
3. Validate against execution history
4. Save to ~/.claude/skills/
5. Mark candidate as promoted

Skill format (following Claude Agent SDK spec):
---
name: skill-name
description: Brief description
max_uses_per_session: 3
---

## Prompt

[Skill-specific instructions...]

## Examples

[Usage examples...]
"""

import hashlib
import logging
from pathlib import Path
from typing import Any

from jarvis.memory import MemoryStore

logger = logging.getLogger(__name__)

# Maximum skills that can be active in a single session
MAX_SKILLS_PER_SESSION = 3

SKILL_TEMPLATE = """---
name: {skill_name}
description: {description}
max_uses_per_session: 3
confidence: {confidence:.2f}
auto_generated: true
---

## Context

This skill was automatically generated after detecting {occurrence_count} similar task patterns.

## Pattern Description

{pattern_description}

## When to Use This Skill

{when_to_use}

## Prompt

{prompt}

## Example Tasks

{examples}

## Validation

Generated from execution records:
{validation_notes}

---
Auto-generated by Jarvis v2.0 Skill Generator
Pattern hash: {pattern_hash}
Confidence: {confidence:.2f}
Occurrences: {occurrence_count}
"""

# GLM prompt template for generating skill instructions
GLM_SKILL_GENERATION_PROMPT = """You are a skill generator for an autonomous coding agent.

Given a recurring pattern observed {occurrence_count} times across task executions, generate a concise, actionable skill prompt.

## Pattern Description
{pattern_description}

## Example Tasks Where This Pattern Occurred
{example_tasks}

## Execution Context
{execution_context}

## Instructions
Generate a skill prompt that:
1. Clearly describes when to apply this skill
2. Provides step-by-step instructions for handling this pattern
3. Includes validation checks to confirm the fix worked
4. Is specific enough to be actionable but general enough to cover variations

Output ONLY the skill prompt text (no markdown headers, no metadata).
"""


def generate_skill_name(pattern_description: str) -> str:
    """Generate a skill name from pattern description.

    Examples:
    - "Fix for: TypeError undefined" -> "fix-typeerror-undefined"
    - "Git workflow commit and push" -> "git-workflow-commit-push"
    """
    # Extract key words
    words = pattern_description.lower().split()
    # Remove common words
    stop_words = {"for", "the", "and", "a", "an", "of", "to", "in", "is", "it"}
    words = [w for w in words if w not in stop_words]
    # Take first 4 words, clean special chars
    words = words[:4]
    words = ["".join(c for c in w if c.isalnum() or c == "-") for w in words]
    return "-".join(words)


def rank_skill_candidates(candidates: list[dict]) -> list[dict]:
    """Rank skill candidates by relevance for session selection.

    Ranking factors (weighted):
    - Confidence score (40%): higher confidence = more reliable
    - Occurrence count (30%): more occurrences = more useful
    - Recency (30%): recently seen patterns are more relevant

    Returns candidates sorted by rank score (highest first).
    """
    import time

    now = time.time()
    ranked = []

    for candidate in candidates:
        confidence = candidate.get("confidence", 0.5)
        occurrences = candidate.get("occurrence_count", 1)
        last_seen = candidate.get("last_seen", 0)

        # Normalize recency: 1.0 for <1hr ago, decays over 7 days
        age_hours = (now - last_seen) / 3600 if last_seen else 168
        recency_score = max(0.0, 1.0 - (age_hours / 168))

        # Normalize occurrence count (log scale, cap at 20)
        import math
        occurrence_score = min(1.0, math.log(occurrences + 1) / math.log(21))

        # Weighted rank score
        rank_score = (
            0.4 * confidence
            + 0.3 * occurrence_score
            + 0.3 * recency_score
        )

        ranked.append({**candidate, "_rank_score": rank_score})

    ranked.sort(key=lambda c: c["_rank_score"], reverse=True)
    return ranked


def select_session_skills(memory: MemoryStore, max_skills: int = MAX_SKILLS_PER_SESSION) -> list[dict]:
    """Select the top-ranked skills for the current session.

    Enforces the hard cap of MAX_SKILLS_PER_SESSION skills per session.
    Returns only the highest-ranked promoted skills.
    """
    promoted = memory.get_skill_candidates(min_occurrences=1, promoted=True)
    if not promoted:
        return []

    ranked = rank_skill_candidates(promoted)
    selected = ranked[:max_skills]

    logger.info(
        f"Selected {len(selected)}/{len(promoted)} skills for session "
        f"(cap: {max_skills})"
    )
    return selected


def detect_skill_worthy_patterns(memory: MemoryStore, min_occurrences: int = 3) -> list[dict]:
    """Detect patterns that should be promoted to skills.

    Args:
        memory: MemoryStore instance
        min_occurrences: Minimum pattern occurrences to consider

    Returns:
        List of skill candidates ready for generation
    """
    candidates = memory.get_skill_candidates(
        min_occurrences=min_occurrences,
        promoted=False,  # Only unpromoted candidates
    )

    logger.info(f"Found {len(candidates)} skill candidates with {min_occurrences}+ occurrences")
    return candidates


async def _generate_prompt_via_glm(
    pattern_description: str,
    occurrence_count: int,
    example_tasks: list[str],
    execution_context: str,
) -> str | None:
    """Generate a skill prompt using GLM 4.7 via the model router.

    Returns the generated prompt text, or None if GLM is unavailable.
    """
    try:
        from jarvis.model_router import get_model_router

        router = get_model_router()

        # Only attempt if cloud API is available
        if not router.qwen3_available and not router.foundation_available:
            # Use the GLM prompt template
            prompt_input = GLM_SKILL_GENERATION_PROMPT.format(
                pattern_description=pattern_description,
                occurrence_count=occurrence_count,
                example_tasks="\n".join(f"- {t}" for t in example_tasks[:5]),
                execution_context=execution_context,
            )

            # Route via the model router for GLM cloud
            try:
                import httpx

                # Use the Claude/GLM API directly for skill generation
                api_key = None
                import os
                api_key = os.environ.get("ANTHROPIC_API_KEY", "")
                if not api_key:
                    return None

                async with httpx.AsyncClient(timeout=30.0) as client:
                    resp = await client.post(
                        "https://api.anthropic.com/v1/messages",
                        headers={
                            "x-api-key": api_key,
                            "anthropic-version": "2023-06-01",
                            "content-type": "application/json",
                        },
                        json={
                            "model": "claude-haiku-4-5-20251001",
                            "max_tokens": 1024,
                            "messages": [{"role": "user", "content": prompt_input}],
                        },
                    )
                    if resp.status_code == 200:
                        data = resp.json()
                        content = data.get("content", [])
                        if content and content[0].get("type") == "text":
                            generated = content[0]["text"].strip()
                            logger.info(f"GLM generated skill prompt ({len(generated)} chars)")
                            return generated
            except Exception as e:
                logger.debug(f"GLM API call failed: {e}")
                return None

    except Exception as e:
        logger.debug(f"GLM skill generation unavailable: {e}")

    return None


async def generate_skill_from_candidate(
    candidate: dict,
    memory: MemoryStore,
    project_path: str,
) -> dict[str, Any]:
    """Generate a SKILL.md file from a pattern candidate.

    Uses GLM 4.7 for prompt generation when available, falls back
    to template-based generation.

    Args:
        candidate: Skill candidate dict from database
        memory: MemoryStore instance
        project_path: Current project path

    Returns:
        dict with skill generation results
    """
    pattern_hash = candidate["pattern_hash"]
    pattern_description = candidate["pattern_description"]
    occurrence_count = candidate["occurrence_count"]
    example_tasks = candidate["example_tasks"]
    confidence = candidate["confidence"]

    # Generate skill name
    skill_name = generate_skill_name(pattern_description)

    # Create brief description
    description = f"Handles: {pattern_description[:100]}"

    # Generate when to use
    when_to_use = f"""Use this skill when encountering tasks similar to:
{chr(10).join(f"- {task}" for task in example_tasks[:3])}

This pattern has occurred {occurrence_count} times in execution history."""

    # Build execution context from records
    execution_context = ""
    for task_id in example_tasks[:3]:
        records = memory.get_execution_records(task_id=task_id, limit=5)
        if records:
            errors = [r["error_message"] for r in records if r.get("error_message")]
            tools = [r["tool_name"] for r in records]
            execution_context += f"Task {task_id}: tools={tools[:5]}, errors={errors[:2]}\n"

    # Attempt GLM-based prompt generation
    prompt = await _generate_prompt_via_glm(
        pattern_description=pattern_description,
        occurrence_count=occurrence_count,
        example_tasks=example_tasks,
        execution_context=execution_context or "No execution context available",
    )

    # Fallback to template-based prompt
    if not prompt:
        prompt = f"""You are handling a recurring pattern that has been seen {occurrence_count} times.

Pattern: {pattern_description}

Follow the established pattern from previous successful executions:
1. Analyze the task to confirm it matches this pattern
2. Apply the validated fix/approach from learning history
3. Test the result
4. Report completion

If this pattern doesn't match, decline gracefully and explain why."""

    # Format examples
    examples = "\n".join(
        f"{i+1}. {task}" for i, task in enumerate(example_tasks[:5])
    )

    # Validation notes
    validation_notes = f"""
- Detected across {occurrence_count} task executions
- Example task IDs: {', '.join(example_tasks[:3])}
- Confidence score: {confidence:.2f}
- Pattern hash: {pattern_hash}
"""

    # Generate skill content
    skill_content = SKILL_TEMPLATE.format(
        skill_name=skill_name,
        description=description,
        pattern_description=pattern_description,
        occurrence_count=occurrence_count,
        when_to_use=when_to_use,
        prompt=prompt,
        examples=examples,
        confidence=confidence,
        validation_notes=validation_notes,
        pattern_hash=pattern_hash,
    )

    return {
        "skill_name": skill_name,
        "skill_content": skill_content,
        "pattern_hash": pattern_hash,
        "confidence": confidence,
    }


def save_skill_to_directory(skill_name: str, skill_content: str) -> Path | None:
    """Save skill to ~/.claude/skills/ directory.

    Args:
        skill_name: Name of the skill (will be slugified)
        skill_content: SKILL.md content

    Returns:
        Path to saved skill file, or None if the file already exists
    """
    # Create skills directory where the Agent SDK expects them
    skills_dir = Path.home() / ".claude" / "skills"
    skills_dir.mkdir(parents=True, exist_ok=True)

    skill_path = skills_dir / f"{skill_name}.md"

    # Don't overwrite existing skills (could be user-edited)
    if skill_path.exists():
        logger.info(f"Skill file already exists, skipping: {skill_path}")
        return None

    skill_path.write_text(skill_content)
    logger.info(f"Saved skill to {skill_path}")
    return skill_path


async def generate_skills_from_patterns(
    memory: MemoryStore,
    project_path: str,
    min_occurrences: int = 3,
    max_skills: int = 5,
) -> dict[str, Any]:
    """Main skill generation pipeline.

    Args:
        memory: MemoryStore instance
        project_path: Current project path
        min_occurrences: Minimum pattern occurrences
        max_skills: Maximum skills to generate in one pass

    Returns:
        dict with generation statistics
    """
    # Detect candidates
    candidates = detect_skill_worthy_patterns(memory, min_occurrences)

    if not candidates:
        logger.info("No skill candidates ready for generation")
        return {
            "skills_generated": 0,
            "candidates_found": 0,
            "skills_saved": [],
        }

    # Rank candidates and enforce session cap
    ranked = rank_skill_candidates(candidates)
    ranked = ranked[:max_skills]

    # Generate skills
    skills_generated = []
    for candidate in ranked:
        try:
            skill_data = await generate_skill_from_candidate(
                candidate, memory, project_path
            )

            # Save skill (checks for existing file to avoid overwriting)
            skill_path = save_skill_to_directory(
                skill_data["skill_name"],
                skill_data["skill_content"],
            )

            if skill_path is None:
                # Skill file already exists â€” skip but still mark promoted
                logger.info(
                    f"Skill '{skill_data['skill_name']}' already exists, marking promoted"
                )
                memory.mark_skill_promoted(candidate["id"])
                continue

            # Mark candidate as promoted only after file is confirmed written
            memory.mark_skill_promoted(candidate["id"])

            skills_generated.append({
                "name": skill_data["skill_name"],
                "path": str(skill_path),
                "confidence": skill_data["confidence"],
                "pattern_hash": skill_data["pattern_hash"],
            })

            logger.info(
                f"Generated skill '{skill_data['skill_name']}' "
                f"(confidence: {skill_data['confidence']:.2f})"
            )

        except Exception as e:
            logger.error(f"Failed to generate skill from candidate {candidate['id']}: {e}")
            continue

    return {
        "skills_generated": len(skills_generated),
        "candidates_found": len(candidates),
        "skills_saved": skills_generated,
    }


async def validate_skill(skill_name: str, memory: MemoryStore) -> dict[str, Any]:
    """Validate a generated skill against execution history.

    Loads the skill file, finds matching execution records, and checks
    whether the pattern described in the skill matches successful
    resolutions in the execution history.

    Args:
        skill_name: Name of the skill to validate
        memory: MemoryStore instance

    Returns:
        dict with validation results
    """
    # Load skill file
    skills_dir = Path.home() / ".claude" / "skills"
    skill_path = skills_dir / f"{skill_name}.md"

    if not skill_path.exists():
        return {
            "skill_name": skill_name,
            "validated": False,
            "success_rate": 0.0,
            "test_count": 0,
            "errors": [f"Skill file not found: {skill_path}"],
        }

    skill_content = skill_path.read_text()

    # Extract pattern hash from skill content
    pattern_hash = None
    for line in skill_content.splitlines():
        if line.startswith("Pattern hash:"):
            pattern_hash = line.split(":", 1)[1].strip()
            break

    if not pattern_hash:
        return {
            "skill_name": skill_name,
            "validated": False,
            "success_rate": 0.0,
            "test_count": 0,
            "errors": ["No pattern hash found in skill file"],
        }

    # Find the skill candidate record
    candidates = memory.get_skill_candidates(min_occurrences=1, promoted=True)
    matching_candidate = None
    for candidate in candidates:
        if candidate["pattern_hash"] == pattern_hash:
            matching_candidate = candidate
            break

    if not matching_candidate:
        return {
            "skill_name": skill_name,
            "validated": False,
            "success_rate": 0.0,
            "test_count": 0,
            "errors": ["No matching skill candidate found in database"],
        }

    # Get execution records for the example tasks
    example_tasks = matching_candidate.get("example_tasks", [])
    successful = 0
    total = 0

    for task_id in example_tasks:
        records = memory.get_execution_records(task_id=task_id)
        if not records:
            continue

        total += 1
        # Check if the task completed successfully
        # (no errors in the last few records)
        last_records = records[-3:] if len(records) >= 3 else records
        has_errors = any(
            r.get("error_message") or r.get("exit_code", 0) != 0
            for r in last_records
        )
        if not has_errors:
            successful += 1

    success_rate = (successful / total) if total > 0 else 0.0
    validated = success_rate >= 0.6 and total >= 2

    return {
        "skill_name": skill_name,
        "validated": validated,
        "success_rate": success_rate,
        "test_count": total,
        "successful": successful,
        "pattern_hash": pattern_hash,
        "errors": [] if validated else [
            f"Validation threshold not met: {success_rate:.0%} success rate "
            f"({successful}/{total} tasks)"
        ],
    }


def copy_bootstrap_skills(project_path: str | None = None) -> list[str]:
    """Copy bootstrap skills to the user's skills directory.

    Copies from bootstrap/skills/coding/ to ~/.claude/skills/
    without overwriting existing files.

    Args:
        project_path: Optional project path for project-local skills

    Returns:
        List of skill names that were copied
    """
    import shutil

    # Source: bootstrap skills bundled with Jarvis
    bootstrap_dir = Path(__file__).parent.parent.parent / "bootstrap" / "skills" / "coding"
    if not bootstrap_dir.exists():
        logger.warning(f"Bootstrap skills directory not found: {bootstrap_dir}")
        return []

    # Destination: user's skills directory
    skills_dir = Path.home() / ".claude" / "skills"
    skills_dir.mkdir(parents=True, exist_ok=True)

    copied = []
    for skill_file in bootstrap_dir.glob("*.md"):
        dest = skills_dir / skill_file.name
        if not dest.exists():
            shutil.copy2(skill_file, dest)
            copied.append(skill_file.stem)
            logger.info(f"Copied bootstrap skill: {skill_file.stem}")
        else:
            logger.debug(f"Bootstrap skill already exists: {skill_file.stem}")

    return copied
